{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/content/drive/MyDrive/Colab_Notebooks/panda_grasp/\"\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Environment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pybullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import difflib\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import torch as th\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "import task\n",
    "from utils.exp_manager import ExperimentManager\n",
    "from utils.utils import ALGOS, StoreDict\n",
    "from custom_policy import *\n",
    "seaborn.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args=None):\n",
    "\n",
    "    # Check if the selected environment is valid\n",
    "    # If it could not be found, suggest the closest match\n",
    "    registered_envs = set(gym.envs.registry.env_specs.keys())\n",
    "    if args.env not in registered_envs:\n",
    "        try:\n",
    "            closest_match = difflib.get_close_matches(\n",
    "                args.env, registered_envs, n=1)[0]\n",
    "        except IndexError:\n",
    "            closest_match = \"'no close match found...'\"\n",
    "        raise ValueError(\n",
    "            f\"{args.env} not found in gym registry, you maybe meant {closest_match}?\")\n",
    "\n",
    "    # If no specific seed is selected, choose a random one\n",
    "    if args.seed < 0:\n",
    "        args.seed = np.random.randint(2 ** 32 - 1, dtype=\"int64\").item()\n",
    "\n",
    "    # Set the random seed across platforms\n",
    "    set_random_seed(args.seed)\n",
    "\n",
    "    # Setting num threads to 1 makes things run faster on cpu\n",
    "    if args.num_threads > 0:\n",
    "        if args.verbose > 1:\n",
    "            print(f\"Setting torch.num_threads to {args.num_threads}\")\n",
    "        th.set_num_threads(args.num_threads)\n",
    "\n",
    "    # Verify that pre-trained agent exists before continuing to train it\n",
    "    if args.trained_agent != \"\":\n",
    "        assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\n",
    "            args.trained_agent\n",
    "        ), \"The trained_agent must be a valid path to a .zip file\"\n",
    "\n",
    "    # If enabled, ensure that the run has a unique ID\n",
    "    uuid_str = f\"_{uuid.uuid4()}\" if args.uuid else \"\"\n",
    "\n",
    "    print(\"=\" * 10, args.env, \"=\" * 10)\n",
    "    print(f\"Seed: {args.seed}\")\n",
    "\n",
    "    exp_manager = ExperimentManager(\n",
    "        args,\n",
    "        args.algo,\n",
    "        args.env,\n",
    "        args.log_folder,\n",
    "        args.tensorboard_log,\n",
    "        args.n_timesteps,\n",
    "        args.eval_freq,\n",
    "        args.eval_episodes,\n",
    "        args.save_freq,\n",
    "        args.hyperparams,\n",
    "        args.env_kwargs,\n",
    "        args.trained_agent,\n",
    "        args.optimize_hyperparameters,\n",
    "        args.storage,\n",
    "        args.study_name,\n",
    "        args.n_trials,\n",
    "        args.n_jobs,\n",
    "        args.sampler,\n",
    "        args.pruner,\n",
    "        n_startup_trials=args.n_startup_trials,\n",
    "        n_evaluations=args.n_evaluations,\n",
    "        truncate_last_trajectory=args.truncate_last_trajectory,\n",
    "        uuid_str=uuid_str,\n",
    "        seed=args.seed,\n",
    "        log_interval=args.log_interval,\n",
    "        save_replay_buffer=args.save_replay_buffer,\n",
    "        \n",
    "        verbose=args.verbose,\n",
    "        vec_env_type=args.vec_env,\n",
    "    )\n",
    "\n",
    "    # Prepare experiment and launch hyperparameter optimization if needed\n",
    "    model = exp_manager.setup_experiment()\n",
    "\n",
    "    if args.optimize_hyperparameters:\n",
    "        exp_manager.hyperparameters_optimization()\n",
    "    else:\n",
    "        exp_manager.learn(model)\n",
    "        exp_manager.save_trained_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Environment and its parameters\n",
    "parser.add_argument(\"--env\", type=str,\n",
    "                        default=\"PandaTouchEnv_color-v0\",\n",
    "                        help=\"environment ID\")\n",
    "parser.add_argument(\"--env-kwargs\", type=str, nargs=\"+\", action=StoreDict,\n",
    "                        help=\"Optional keyword argument to pass to the env constructor\")\n",
    "parser.add_argument(\"--vec-env\", type=str, choices=[\"dummy\", \"subproc\"],\n",
    "                        default=\"dummy\",\n",
    "                        help=\"VecEnv type\")\n",
    "\n",
    "# Algorithm\n",
    "parser.add_argument(\"--algo\", type=str, choices=list(ALGOS.keys()), required=False,\n",
    "                        default=\"sac\", help=\"RL Algorithm\")\n",
    "parser.add_argument(\"-params\", \"--hyperparams\", type=str, nargs=\"+\", action=StoreDict,\n",
    "                        help=\"Overwrite hyperparameter (e.g. learning_rate:0.01 train_freq:10)\")\n",
    "parser.add_argument(\"--num-threads\", type=int,\n",
    "                        default=-1,\n",
    "                        help=\"Number of threads for PyTorch (-1 to use default)\")\n",
    "\n",
    "# Training duration\n",
    "parser.add_argument(\"-n\", \"--n-timesteps\", type=int,\n",
    "                        default=50000,\n",
    "                        help=\"Overwrite the number of timesteps\")\n",
    "\n",
    "# Continue training an already trained agent\n",
    "parser.add_argument(\"-i\", \"--trained-agent\", type=str,\n",
    "                        default=\"\",\n",
    "                        help=\"Path to a pretrained agent to continue training\")\n",
    "\n",
    "# Random seed\n",
    "parser.add_argument(\"--seed\", type=int,\n",
    "                        default=42,\n",
    "                        help=\"Random generator seed\")\n",
    "\n",
    "# Saving of model\n",
    "parser.add_argument(\"--save-freq\", type=int,\n",
    "                        default=1000,\n",
    "                        help=\"Save the model every n steps (if negative, no checkpoint)\")\n",
    "parser.add_argument(\"--save-replay-buffer\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Save the replay buffer too (when applicable)\")\n",
    "\n",
    "# Pre-load a replay buffer and start training on it\n",
    "parser.add_argument(\"--preload-replay-buffer\", type=str,\n",
    "                        default=\"model\",\n",
    "                        help=\"Path to a replay buffer that should be preloaded before starting the training process\")\n",
    "\n",
    "# Logging\n",
    "parser.add_argument(\"-f\", \"--log-folder\", type=str,\n",
    "                        default=\"logs\",\n",
    "                        help=\"Log folder\")\n",
    "parser.add_argument(\"-tb\", \"--tensorboard-log\", type=str,\n",
    "                        default=\"tensorboard_logs\",\n",
    "                        help=\"Tensorboard log dir\")\n",
    "parser.add_argument(\"--log-interval\", type=int,\n",
    "                        default=-1,\n",
    "                        help=\"Override log interval (default: -1, no change)\")\n",
    "parser.add_argument(\"-uuid\", \"--uuid\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Ensure that the run has a unique ID\")\n",
    "\n",
    "# Hyperparameter optimization\n",
    "parser.add_argument(\"-optimize\", \"--optimize-hyperparameters\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Run hyperparameters search\")\n",
    "parser.add_argument(\"--sampler\", type=str, choices=[\"random\", \"tpe\", \"skopt\"],\n",
    "                        default=\"tpe\",\n",
    "                        help=\"Sampler to use when optimizing hyperparameters\")\n",
    "parser.add_argument(\"--pruner\", type=str, choices=[\"halving\", \"median\", \"none\"],\n",
    "                        default=\"median\",\n",
    "                        help=\"Pruner to use when optimizing hyperparameters\")\n",
    "parser.add_argument(\"--n-trials\", type=int,\n",
    "                        default=10,\n",
    "                        help=\"Number of trials for optimizing hyperparameters\")\n",
    "parser.add_argument(\"--n-startup-trials\", type=int,\n",
    "                        default=5,\n",
    "                        help=\"Number of trials before using optuna sampler\")\n",
    "parser.add_argument(\"--n-evaluations\", type=int,\n",
    "                        default=2,\n",
    "                        help=\"Number of evaluations for hyperparameter optimization\")\n",
    "parser.add_argument(\"--n-jobs\", type=int,\n",
    "                        default=1,\n",
    "                        help=\"Number of parallel jobs when optimizing hyperparameters\")\n",
    "parser.add_argument(\"--storage\", type=str,\n",
    "                        default=None,\n",
    "                        help=\"Database storage path if distributed optimization should be used\")\n",
    "parser.add_argument(\"--study-name\", type=str,\n",
    "                        default=None,\n",
    "                        help=\"Study name for distributed optimization\")\n",
    "\n",
    "# Evaluation\n",
    "parser.add_argument(\"--eval-freq\", type=int,\n",
    "                        default=-1,\n",
    "                        help=\"Evaluate the agent every n steps (if negative, no evaluation)\")\n",
    "parser.add_argument(\"--eval-episodes\", type=int,\n",
    "                        default=10,\n",
    "                        help=\"Number of episodes to use for evaluation\")\n",
    "\n",
    "# Verbosity\n",
    "parser.add_argument(\"--verbose\", type=int,\n",
    "                        default=1,\n",
    "                        help=\"Verbose mode (0: no output, 1: INFO)\")\n",
    "\n",
    "# HER specifics\n",
    "parser.add_argument(\n",
    "        \"--truncate-last-trajectory\",\n",
    "        help=\"When using HER with online sampling the last trajectory \"\n",
    "        \"in the replay buffer will be truncated after reloading the replay buffer.\",\n",
    "        default=True,\n",
    "        type=bool,\n",
    ")\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "sac\n"
     ]
    }
   ],
   "source": [
    "print(args.preload_replay_buffer)\n",
    "print(args.algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== PandaTouchEnv_color-v0 ==========\n",
      "Seed: 42\n",
      "OrderedDict([('batch_size', 32),\n",
      "             ('buffer_size', 25000),\n",
      "             ('ent_coef', 'auto_0.1'),\n",
      "             ('env_wrapper',\n",
      "              ['task.wrapper.ProcessFrame64',\n",
      "               'task.wrapper.ImageToPyTorch',\n",
      "               'task.wrapper.MoveConstraint',\n",
      "               {'task.wrapper.TimeLimit': {'max_episode_steps': 500}}]),\n",
      "             ('gamma', 0.95),\n",
      "             ('gradient_steps', 1),\n",
      "             ('learning_rate', 'lin_0.0003'),\n",
      "             ('learning_starts', 0),\n",
      "             ('n_timesteps', 50000),\n",
      "             ('noise_std', 0.025),\n",
      "             ('noise_type', 'normal'),\n",
      "             ('optimize_memory_usage', True),\n",
      "             ('policy', 'CustomResNetPolicy'),\n",
      "             ('policy_kwargs', {'n_critics': 2, 'net_arch': [128, 128]}),\n",
      "             ('target_entropy', 'auto'),\n",
      "             ('tau', 0.01),\n",
      "             ('train_freq', 1)])\n",
      "Using 1 environments\n",
      "Overwriting n_timesteps with n=50000\n",
      "Applying normal noise with std 0.025\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yi/.cache/torch/hub/pytorch_vision_v0.9.0\n",
      "Using cache found in /home/yi/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-19afe20959fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-2109083d06c9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Prepare experiment and launch hyperparameter optimization if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_hyperparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Thesis/panda_grasp/utils/exp_manager.py\u001b[0m in \u001b[0;36msetup_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyperparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             )\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, optimize_memory_usage, ent_coef, target_update_interval, target_entropy, use_sde, sde_sample_freq, use_sde_at_warmup, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36m_setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_aliases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Target entropy is used when learning the entropy coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36m_setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pytype:disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         )\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Convert train freq parameter to TrainFreq object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "train(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-f56d0c02a80c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-f56d0c02a80c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir ./tensorboard_logs/PandaGraspEnv_color-v0/\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir ./tensorboard_logs/PandaGraspEnv_color-v0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79250dea48bd052fcbb33c25808a91c9ec53b051d004b31882d2537f33ff35da"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('drl_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "79250dea48bd052fcbb33c25808a91c9ec53b051d004b31882d2537f33ff35da"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}