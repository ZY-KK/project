{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd079250dea48bd052fcbb33c25808a91c9ec53b051d004b31882d2537f33ff35da",
   "display_name": "Python 3.7.10 64-bit ('drl_env': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "79250dea48bd052fcbb33c25808a91c9ec53b051d004b31882d2537f33ff35da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/content/drive/MyDrive/Colab_Notebooks/panda_grasp/\"\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Environment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pybullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from utils import exp_manager\n",
    "from utils.exp_manager import ExperimentManager\n",
    "from task.Grasp.PandaGraspEnv import PandaGraspEnv\n",
    "from utils.utils import ALGOS,StoreDict\n",
    "import numpy as np\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "import torch as th\n",
    "import uuid\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args=None):\n",
    "\n",
    "    # Check if the selected environment is valid\n",
    "    # If it could not be found, suggest the closest match\n",
    "    registered_envs = set(gym.envs.registry.env_specs.keys())\n",
    "    if args.env not in registered_envs:\n",
    "        try:\n",
    "            closest_match = difflib.get_close_matches(\n",
    "                args.env, registered_envs, n=1)[0]\n",
    "        except IndexError:\n",
    "            closest_match = \"'no close match found...'\"\n",
    "        raise ValueError(\n",
    "            f\"{args.env} not found in gym registry, you maybe meant {closest_match}?\")\n",
    "\n",
    "    # If no specific seed is selected, choose a random one\n",
    "    if args.seed < 0:\n",
    "        args.seed = np.random.randint(2 ** 32 - 1, dtype=\"int64\").item()\n",
    "\n",
    "    # Set the random seed across platforms\n",
    "    set_random_seed(args.seed)\n",
    "\n",
    "    # Setting num threads to 1 makes things run faster on cpu\n",
    "    if args.num_threads > 0:\n",
    "        if args.verbose > 1:\n",
    "            print(f\"Setting torch.num_threads to {args.num_threads}\")\n",
    "        th.set_num_threads(args.num_threads)\n",
    "\n",
    "    # Verify that pre-trained agent exists before continuing to train it\n",
    "    if args.trained_agent != \"\":\n",
    "        assert args.trained_agent.endswith(\".zip\") and os.path.isfile(\n",
    "            args.trained_agent\n",
    "        ), \"The trained_agent must be a valid path to a .zip file\"\n",
    "\n",
    "    # If enabled, ensure that the run has a unique ID\n",
    "    uuid_str = f\"_{uuid.uuid4()}\" if args.uuid else \"\"\n",
    "\n",
    "    print(\"=\" * 10, args.env, \"=\" * 10)\n",
    "    print(f\"Seed: {args.seed}\")\n",
    "\n",
    "    exp_manager = ExperimentManager(\n",
    "        args,\n",
    "        args.algo,\n",
    "        args.env,\n",
    "        args.log_folder,\n",
    "        args.tensorboard_log,\n",
    "        args.n_timesteps,\n",
    "        args.eval_freq,\n",
    "        args.eval_episodes,\n",
    "        args.save_freq,\n",
    "        args.hyperparams,\n",
    "        args.env_kwargs,\n",
    "        args.trained_agent,\n",
    "        args.optimize_hyperparameters,\n",
    "        args.storage,\n",
    "        args.study_name,\n",
    "        args.n_trials,\n",
    "        args.n_jobs,\n",
    "        args.sampler,\n",
    "        args.pruner,\n",
    "        n_startup_trials=args.n_startup_trials,\n",
    "        n_evaluations=args.n_evaluations,\n",
    "        truncate_last_trajectory=args.truncate_last_trajectory,\n",
    "        uuid_str=uuid_str,\n",
    "        seed=args.seed,\n",
    "        log_interval=args.log_interval,\n",
    "        save_replay_buffer=args.save_replay_buffer,\n",
    "        preload_replay_buffer=args.preload_replay_buffer,\n",
    "        verbose=args.verbose,\n",
    "        vec_env_type=args.vec_env,\n",
    "    )\n",
    "\n",
    "    # Prepare experiment and launch hyperparameter optimization if needed\n",
    "    model = exp_manager.setup_experiment()\n",
    "\n",
    "    if args.optimize_hyperparameters:\n",
    "        exp_manager.hyperparameters_optimization()\n",
    "    else:\n",
    "        exp_manager.learn(model)\n",
    "        exp_manager.save_trained_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Environment and its parameters\n",
    "parser.add_argument(\"--env\", type=str,\n",
    "                        default=\"Reach-Gazebo-v0\",\n",
    "                        help=\"environment ID\")\n",
    "parser.add_argument(\"--env-kwargs\", type=str, nargs=\"+\", action=StoreDict,\n",
    "                        help=\"Optional keyword argument to pass to the env constructor\")\n",
    "parser.add_argument(\"--vec-env\", type=str, choices=[\"dummy\", \"subproc\"],\n",
    "                        default=\"dummy\",\n",
    "                        help=\"VecEnv type\")\n",
    "\n",
    "# Algorithm\n",
    "parser.add_argument(\"--algo\", type=str, choices=list(ALGOS.keys()), required=False,\n",
    "                        default=\"ppo\", help=\"RL Algorithm\")\n",
    "parser.add_argument(\"-params\", \"--hyperparams\", type=str, nargs=\"+\", action=StoreDict,\n",
    "                        help=\"Overwrite hyperparameter (e.g. learning_rate:0.01 train_freq:10)\")\n",
    "parser.add_argument(\"--num-threads\", type=int,\n",
    "                        default=-1,\n",
    "                        help=\"Number of threads for PyTorch (-1 to use default)\")\n",
    "\n",
    "# Training duration\n",
    "parser.add_argument(\"-n\", \"--n-timesteps\", type=int,\n",
    "                        default=150000,\n",
    "                        help=\"Overwrite the number of timesteps\")\n",
    "\n",
    "# Continue training an already trained agent\n",
    "parser.add_argument(\"-i\", \"--trained-agent\", type=str,\n",
    "                        default=\"\",\n",
    "                        help=\"Path to a pretrained agent to continue training\")\n",
    "\n",
    "# Random seed\n",
    "parser.add_argument(\"--seed\", type=int,\n",
    "                        default=42,\n",
    "                        help=\"Random generator seed\")\n",
    "\n",
    "# Saving of model\n",
    "parser.add_argument(\"--save-freq\", type=int,\n",
    "                        default=10000,\n",
    "                        help=\"Save the model every n steps (if negative, no checkpoint)\")\n",
    "parser.add_argument(\"--save-replay-buffer\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Save the replay buffer too (when applicable)\")\n",
    "\n",
    "# Pre-load a replay buffer and start training on it\n",
    "parser.add_argument(\"--preload-replay-buffer\", type=str,\n",
    "                        default=\"\",\n",
    "                        help=\"Path to a replay buffer that should be preloaded before starting the training process\")\n",
    "\n",
    "# Logging\n",
    "parser.add_argument(\"-f\", \"--log-folder\", type=str,\n",
    "                        default=\"logs\",\n",
    "                        help=\"Log folder\")\n",
    "parser.add_argument(\"-tb\", \"--tensorboard-log\", type=str,\n",
    "                        default=\"tensorboard_logs\",\n",
    "                        help=\"Tensorboard log dir\")\n",
    "parser.add_argument(\"--log-interval\", type=int,\n",
    "                        default=-1,\n",
    "                        help=\"Override log interval (default: -1, no change)\")\n",
    "parser.add_argument(\"-uuid\", \"--uuid\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Ensure that the run has a unique ID\")\n",
    "\n",
    "# Hyperparameter optimization\n",
    "parser.add_argument(\"-optimize\", \"--optimize-hyperparameters\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"Run hyperparameters search\")\n",
    "parser.add_argument(\"--sampler\", type=str, choices=[\"random\", \"tpe\", \"skopt\"],\n",
    "                        default=\"tpe\",\n",
    "                        help=\"Sampler to use when optimizing hyperparameters\")\n",
    "parser.add_argument(\"--pruner\", type=str, choices=[\"halving\", \"median\", \"none\"],\n",
    "                        default=\"median\",\n",
    "                        help=\"Pruner to use when optimizing hyperparameters\")\n",
    "parser.add_argument(\"--n-trials\", type=int,\n",
    "                        default=10,\n",
    "                        help=\"Number of trials for optimizing hyperparameters\")\n",
    "parser.add_argument(\"--n-startup-trials\", type=int,\n",
    "                        default=5,\n",
    "                        help=\"Number of trials before using optuna sampler\")\n",
    "parser.add_argument(\"--n-evaluations\", type=int,\n",
    "                        default=2,\n",
    "                        help=\"Number of evaluations for hyperparameter optimization\")\n",
    "parser.add_argument(\"--n-jobs\", type=int,\n",
    "                        default=1,\n",
    "                        help=\"Number of parallel jobs when optimizing hyperparameters\")\n",
    "parser.add_argument(\"--storage\", type=str,\n",
    "                        default=None,\n",
    "                        help=\"Database storage path if distributed optimization should be used\")\n",
    "parser.add_argument(\"--study-name\", type=str,\n",
    "                        default=None,\n",
    "                        help=\"Study name for distributed optimization\")\n",
    "\n",
    "# Evaluation\n",
    "parser.add_argument(\"--eval-freq\", type=int,\n",
    "                        default=-1,\n",
    "                        help=\"Evaluate the agent every n steps (if negative, no evaluation)\")\n",
    "parser.add_argument(\"--eval-episodes\", type=int,\n",
    "                        default=5,\n",
    "                        help=\"Number of episodes to use for evaluation\")\n",
    "\n",
    "# Verbosity\n",
    "parser.add_argument(\"--verbose\", type=int,\n",
    "                        default=1,\n",
    "                        help=\"Verbose mode (0: no output, 1: INFO)\")\n",
    "\n",
    "# HER specifics\n",
    "parser.add_argument(\n",
    "        \"--truncate-last-trajectory\",\n",
    "        help=\"When using HER with online sampling the last trajectory \"\n",
    "        \"in the replay buffer will be truncated after reloading the replay buffer.\",\n",
    "        default=True,\n",
    "        type=bool,\n",
    ")\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args=args)"
   ]
  }
 ]
}